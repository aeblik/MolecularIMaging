{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dave-\\anaconda3\\envs\\MoIm\\Lib\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "# Load SAM Model\n",
    "model_type = \"vit_l\"\n",
    "sam = sam_model_registry[model_type](checkpoint=\"./sam_vit_l_0b3195.pth\")\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts a unique identifier from a filename using a regular expression pattern.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The filename to extract the identifier from.\n",
    "\n",
    "    Returns:\n",
    "        str: A unique identifier based on the filename, formatted as \"<well>_<timepoint>\".\n",
    "        None: If the filename does not match the expected pattern.\n",
    "    \"\"\"\n",
    "    match = re.match(r\"^([A-D]\\d+_\\d+).*_(\\d{3})\\.tif$\", filename)\n",
    "    return f\"{match.group(1)}_{match.group(2)}\" if match else None\n",
    "\n",
    "def split_mask(mask: np.array) -> tuple:\n",
    "    \"\"\"\n",
    "    Splits a mask into two regions: head (first one-third) and tail (remaining two-thirds).\n",
    "\n",
    "    Args:\n",
    "        mask (np.array): A binary mask of the whole fish.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two numpy arrays representing the head mask and the tail mask.\n",
    "    \"\"\"\n",
    "    split_index = mask.shape[1] // 3  # Compute the index for one-third of the image width\n",
    "\n",
    "    head_mask = np.zeros_like(mask)  # Mask for the head (first one-third)\n",
    "    tail_mask = np.zeros_like(mask)  # Mask for the tail (remaining two-thirds)\n",
    "\n",
    "    # Assign regions to the respective masks\n",
    "    head_mask[:, :split_index] = mask[:, :split_index]  # First one-third (head)\n",
    "    tail_mask[:, split_index:] = mask[:, split_index:]  # Remaining two-thirds (tail)\n",
    "\n",
    "    return head_mask, tail_mask\n",
    "\n",
    "def process_images(input_dir: str, output_dir: str, \n",
    "                   save_masks: bool = True, save_masked_images: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes pairs of 'Phase Contrast' and 'GFP' images to generate binary masks, \n",
    "    calculate GFP intensity for whole fish, head, and tail regions, and save results.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Directory containing input TIF images.\n",
    "        output_dir (str): Directory to save masks, masked images, and results.\n",
    "        save_masks (bool): Whether to save the generated masks.\n",
    "        save_masked_images (bool): Whether to save the GFP images masked by fish, head, and tail masks.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing GFP intensity data for each image pair.\n",
    "    \"\"\"\n",
    "    # Define directories for saving outputs\n",
    "    phase_mask_dir = os.path.join(output_dir, \"phase_masks\")\n",
    "    head_mask_dir = os.path.join(output_dir, \"head_masks\")\n",
    "    tail_mask_dir = os.path.join(output_dir, \"tail_masks\")\n",
    "    masked_images_dir = os.path.join(output_dir, \"masked_images\")  # Folder for masked images\n",
    "    masked_fish_dir = os.path.join(masked_images_dir, \"fish\")\n",
    "    masked_head_dir = os.path.join(masked_images_dir, \"head\")\n",
    "    masked_tail_dir = os.path.join(masked_images_dir, \"tail\")\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if save_masks:\n",
    "        os.makedirs(phase_mask_dir, exist_ok=True)\n",
    "        os.makedirs(head_mask_dir, exist_ok=True)\n",
    "        os.makedirs(tail_mask_dir, exist_ok=True)\n",
    "    if save_masked_images:\n",
    "        os.makedirs(masked_images_dir, exist_ok=True)\n",
    "        os.makedirs(masked_fish_dir, exist_ok=True)\n",
    "        os.makedirs(masked_head_dir, exist_ok=True)\n",
    "        os.makedirs(masked_tail_dir, exist_ok=True)\n",
    "\n",
    "    # Collect Phase Contrast and GFP image pairs\n",
    "    phase_contrast_files = {}\n",
    "    gfp_files = {}\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith(\".tif\"):\n",
    "            identifier = get_identifier(file_name)\n",
    "            if identifier:\n",
    "                if \"Phase Contrast\" in file_name:\n",
    "                    phase_contrast_files[identifier] = file_name\n",
    "                elif \"GFP\" in file_name:\n",
    "                    gfp_files[identifier] = file_name\n",
    "\n",
    "    gfp_intensity_results = []  # To store the results\n",
    "\n",
    "    # Process each image pair\n",
    "    for i, (identifier, phase_file) in enumerate(phase_contrast_files.items()):\n",
    "        if identifier in gfp_files:\n",
    "            try:\n",
    "                phase_path = os.path.join(input_dir, phase_file)\n",
    "                gfp_path = os.path.join(input_dir, gfp_files[identifier])\n",
    "                \n",
    "                # Load and preprocess Phase Contrast image\n",
    "                phase_image = Image.open(phase_path)\n",
    "                phase_np = np.array(phase_image, dtype=np.uint16)\n",
    "                phase_np = (phase_np / phase_np.max() * 255).astype(np.uint8)\n",
    "                phase_rgb = np.stack([phase_np] * 3, axis=-1)\n",
    "\n",
    "                predictor.set_image(phase_rgb)\n",
    "\n",
    "                # Generate primary mask\n",
    "                input_point = np.array([[phase_rgb.shape[1] // 2, phase_rgb.shape[0] // 2]])\n",
    "                input_label = np.array([1])\n",
    "                masks, scores, _ = predictor.predict(\n",
    "                    point_coords=input_point,\n",
    "                    point_labels=input_label,\n",
    "                    multimask_output=False\n",
    "                )\n",
    "                primary_mask = masks[0]\n",
    "\n",
    "                # Save whole fish mask\n",
    "                if save_masks:\n",
    "                    mask_output_path = os.path.join(phase_mask_dir, f\"mask_{identifier}.png\")\n",
    "                    Image.fromarray((primary_mask * 255).astype(np.uint8)).save(mask_output_path)\n",
    "\n",
    "                # Split mask into head and tail\n",
    "                head_mask, tail_mask = split_mask(primary_mask)\n",
    "\n",
    "                # Save head and tail masks\n",
    "                if save_masks:\n",
    "                    head_mask_output_path = os.path.join(head_mask_dir, f\"head_mask_{identifier}.png\")\n",
    "                    tail_mask_output_path = os.path.join(tail_mask_dir, f\"tail_mask_{identifier}.png\")\n",
    "                    Image.fromarray((head_mask * 255).astype(np.uint8)).save(head_mask_output_path)\n",
    "                    Image.fromarray((tail_mask * 255).astype(np.uint8)).save(tail_mask_output_path)\n",
    "\n",
    "                # Load GFP image\n",
    "                gfp_image = Image.open(gfp_path)\n",
    "                gfp_np = np.array(gfp_image, dtype=np.uint16)\n",
    "\n",
    "                # Calculate GFP intensities for whole fish, head, and tail\n",
    "                gfp_values_within_fish = gfp_np[primary_mask > 0]\n",
    "                mean_gfp_intensity = gfp_values_within_fish.mean() if gfp_values_within_fish.size > 0 else 0\n",
    "                total_gfp_intensity = gfp_values_within_fish.sum()\n",
    "\n",
    "                gfp_values_within_head = gfp_np[head_mask > 0]\n",
    "                mean_gfp_head = gfp_values_within_head.mean() if gfp_values_within_head.size > 0 else 0\n",
    "                total_gfp_head = gfp_values_within_head.sum()\n",
    "\n",
    "                gfp_values_within_tail = gfp_np[tail_mask > 0]\n",
    "                mean_gfp_tail = gfp_values_within_tail.mean() if gfp_values_within_tail.size > 0 else 0\n",
    "                total_gfp_tail = gfp_values_within_tail.sum()\n",
    "\n",
    "                # Save masked GFP images\n",
    "                if save_masked_images:\n",
    "                    gfp_masked = gfp_np * primary_mask\n",
    "                    head_masked = gfp_np * head_mask\n",
    "                    tail_masked = gfp_np * tail_mask\n",
    "\n",
    "                    fish_output_path = os.path.join(masked_fish_dir, f\"masked_fish_{identifier}.png\")\n",
    "                    head_output_path = os.path.join(masked_head_dir, f\"masked_head_{identifier}.png\")\n",
    "                    tail_output_path = os.path.join(masked_tail_dir, f\"masked_tail_{identifier}.png\")\n",
    "\n",
    "                    Image.fromarray(gfp_masked.astype(np.uint16)).save(fish_output_path)\n",
    "                    Image.fromarray(head_masked.astype(np.uint16)).save(head_output_path)\n",
    "                    Image.fromarray(tail_masked.astype(np.uint16)).save(tail_output_path)\n",
    "\n",
    "                # Append GFP intensity results\n",
    "                gfp_intensity_results.append({\n",
    "                    \"Identifier\": identifier,\n",
    "                    \"Mean_GFP_Intensity\": mean_gfp_intensity,\n",
    "                    \"Total_GFP_Intensity\": total_gfp_intensity,\n",
    "                    \"Mean_GFP_Head\": mean_gfp_head,\n",
    "                    \"Total_GFP_Head\": total_gfp_head,\n",
    "                    \"Mean_GFP_Tail\": mean_gfp_tail,\n",
    "                    \"Total_GFP_Tail\": total_gfp_tail\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {identifier}: {e}\")\n",
    "\n",
    "        # Display progress\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(phase_contrast_files)} image pairs.\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame(gfp_intensity_results)\n",
    "    csv_output_path = os.path.join(output_dir, \"gfp_intensity_results_vit_l.csv\")\n",
    "    results_df.to_csv(csv_output_path, index=False)\n",
    "    \n",
    "    print(f\"Results saved to {csv_output_path}\") \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "input_dir = r\"C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\test_images\"\n",
    "output_dir = r\"C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\test_images\\output1\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5/8 image pairs.\n",
      "Results saved to C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\test_images\\output1\\gfp_intensity_results_vit_l.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the function\n",
    "gfp_intensity_results_df = process_images(input_dir, output_dir, save_masks=True, save_masked_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"./gfp_intensity_results_vit_l.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- Data Preprocessing ---\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the input DataFrame by extracting treatment, group, and time information,\n",
    "    calculating noise-corrected GFP intensity values, and summarizing the blank well data.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing GFP intensity results.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The processed DataFrame with noise-corrected GFP intensities and\n",
    "                      additional grouping information.\n",
    "    \"\"\"\n",
    "    # Extract group (well rows A-D) and treatment information\n",
    "    df['Group'] = df['Identifier'].str.extract(r'([A-D])')[0]\n",
    "    df['Treatment'] = df['Group'].map({\n",
    "        'A': 'MEndoB',\n",
    "        'B': 'Vancomycin',\n",
    "        'C': 'Control',\n",
    "        'D': 'Blank'\n",
    "    })\n",
    "\n",
    "    # Extract time from the Identifier (e.g., \"_001\" -> 0 min, \"_002\" -> 15 min, etc.)\n",
    "    df['Time'] = (df['Identifier'].str.extract(r'_(\\d+)$').astype(int) - 1) * 15\n",
    "\n",
    "    # Calculate the mean intensity of the blank wells (D4-D6) for noise correction\n",
    "    blank_summary = (\n",
    "        df[df['Treatment'] == 'Blank']\n",
    "        .groupby('Time')\n",
    "        .agg(\n",
    "            Blank_Mean_GFP_Intensity=('Mean_GFP_Intensity', 'mean'),\n",
    "            Blank_Mean_Total_Intensity=('Total_GFP_Intensity', 'mean'),\n",
    "            Blank_Mean_Head_Intensity=('Mean_GFP_Head', 'mean'),\n",
    "            Blank_Mean_Tail_Intensity=('Mean_GFP_Tail', 'mean')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Merge blank well data with the main DataFrame for noise correction\n",
    "    df = pd.merge(df, blank_summary, on='Time', how='left')\n",
    "\n",
    "    # Apply noise correction for GFP intensities (whole fish, head, and tail)\n",
    "    df['Corrected_Mean_GFP_Intensity'] = df['Mean_GFP_Intensity'] - df['Blank_Mean_GFP_Intensity']\n",
    "    df['Corrected_Total_GFP_Intensity'] = df['Total_GFP_Intensity'] - df['Blank_Mean_Total_Intensity']\n",
    "    df['Corrected_Mean_Head_Intensity'] = df['Mean_GFP_Head'] - df['Blank_Mean_Head_Intensity']\n",
    "    df['Corrected_Total_Head_Intensity'] = df['Total_GFP_Head'] - df['Blank_Mean_Head_Intensity']\n",
    "    df['Corrected_Mean_Tail_Intensity'] = df['Mean_GFP_Tail'] - df['Blank_Mean_Tail_Intensity']\n",
    "    df['Corrected_Total_Tail_Intensity'] = df['Total_GFP_Tail'] - df['Blank_Mean_Tail_Intensity']\n",
    "\n",
    "    # Exclude blank wells from the dataset for further analysis\n",
    "    df = df[df['Treatment'] != 'Blank']\n",
    "\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Group by Treatment and Time to calculate summary statistics\n",
    "def summarize_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summarize the input DataFrame by grouping data by treatment and time,\n",
    "    and calculating the mean and standard error for GFP intensities.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with noise-corrected GFP intensities.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A summary DataFrame with mean and SEM values for each region.\n",
    "    \"\"\"\n",
    "    summary = df.groupby(['Treatment', 'Time']).agg(\n",
    "        Whole_Mean=('Corrected_Mean_GFP_Intensity', 'mean'),\n",
    "        Whole_SEM=('Corrected_Mean_GFP_Intensity', 'sem'),\n",
    "        Head_Mean=('Corrected_Mean_Head_Intensity', 'mean'),\n",
    "        Head_SEM=('Corrected_Mean_Head_Intensity', 'sem'),\n",
    "        Tail_Mean=('Corrected_Mean_Tail_Intensity', 'mean'),\n",
    "        Tail_SEM=('Corrected_Mean_Tail_Intensity', 'sem'),\n",
    "    ).reset_index()\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Generate summary data for visualization\n",
    "summary = summarize_data(df)\n",
    "\n",
    "# Define custom colors for better visualization\n",
    "colors = {\n",
    "    'Control': ['#4C72B0', '#92C6FF', '#1F77B4'],  # Blue shades\n",
    "    'MEndoB': ['#55A868', '#88CCAA', '#228833'],   # Green shades\n",
    "    'Vancomycin': ['#C44E52', '#FF8884', '#AA3377']  # Red shades\n",
    "}\n",
    "\n",
    "# --- Line Plot for Mean GFP Intensities ---\n",
    "def plot_gfp_intensity(summary: pd.DataFrame, colors: dict):\n",
    "    \"\"\"\n",
    "    Plot the corrected mean GFP intensities over time for different treatments and regions.\n",
    "\n",
    "    Args:\n",
    "        summary (pd.DataFrame): The summary DataFrame with mean and SEM values.\n",
    "        colors (dict): A dictionary mapping treatments to color palettes for plotting.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a line plot with subplots for each treatment.\n",
    "    \"\"\"\n",
    "    treatments = summary['Treatment'].unique()\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "    for ax, treatment in zip(axes, treatments):\n",
    "        subset = summary[summary['Treatment'] == treatment]\n",
    "\n",
    "        # Plot each region (Whole, Head, Tail) with error bars\n",
    "        ax.errorbar(subset['Time'], subset['Whole_Mean'], yerr=subset['Whole_SEM'], \n",
    "                    label=\"Whole\", linestyle='-', marker='o', color=colors[treatment][0])\n",
    "        ax.errorbar(subset['Time'], subset['Head_Mean'], yerr=subset['Head_SEM'], \n",
    "                    label=\"Head\", linestyle='--', marker='x', color=colors[treatment][1])\n",
    "        ax.errorbar(subset['Time'], subset['Tail_Mean'], yerr=subset['Tail_SEM'], \n",
    "                    label=\"Tail\", linestyle=':', marker='s', color=colors[treatment][2])\n",
    "\n",
    "        # Set titles and axis labels\n",
    "        ax.set_title(treatment)\n",
    "        ax.set_xlabel(\"Time [min]\")\n",
    "        ax.grid()\n",
    "\n",
    "        # Add legend for the subplot\n",
    "        ax.legend(title=\"Region\")\n",
    "\n",
    "    # Set shared y-axis label\n",
    "    axes[0].set_ylabel(\"Corrected Mean GFP Intensity\")\n",
    "\n",
    "    # Add a shared title and adjust layout\n",
    "    fig.suptitle(\"Corrected Mean GFP Intensity Over Time by Region and Treatment\", fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Plot the results\n",
    "plot_gfp_intensity(summary, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_total_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summarize the input DataFrame by grouping data by treatment and time,\n",
    "    and calculating the mean and standard error for total GFP intensities.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with noise-corrected GFP intensities.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A summary DataFrame with mean and SEM values for total GFP intensities.\n",
    "    \"\"\"\n",
    "    summary_total = df.groupby(['Treatment', 'Time']).agg(\n",
    "        Whole_Total=('Corrected_Total_GFP_Intensity', 'mean'),\n",
    "        Whole_SEM=('Corrected_Total_GFP_Intensity', 'sem'),\n",
    "        Head_Total=('Corrected_Total_Head_Intensity', 'mean'),\n",
    "        Head_SEM=('Corrected_Total_Head_Intensity', 'sem'),\n",
    "        Tail_Total=('Corrected_Total_Tail_Intensity', 'mean'),\n",
    "        Tail_SEM=('Corrected_Total_Tail_Intensity', 'sem'),\n",
    "    ).reset_index()\n",
    "\n",
    "    return summary_total\n",
    "\n",
    "# Summarize the data for total GFP intensities\n",
    "summary_total = summarize_total_data(df)\n",
    "\n",
    "def plot_total_gfp_intensity(summary_total: pd.DataFrame, colors: dict):\n",
    "    \"\"\"\n",
    "    Plot the corrected total GFP intensities over time for different treatments and regions.\n",
    "\n",
    "    Args:\n",
    "        summary_total (pd.DataFrame): The summary DataFrame with total GFP intensity means and SEM values.\n",
    "        colors (dict): A dictionary mapping treatments to color palettes for plotting.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a line plot with subplots for each treatment.\n",
    "    \"\"\"\n",
    "    treatments = summary_total['Treatment'].unique()\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "    for ax, treatment in zip(axes, treatments):\n",
    "        subset = summary_total[summary_total['Treatment'] == treatment]\n",
    "\n",
    "        # Plot each region (Whole, Head, Tail) with error bars\n",
    "        ax.errorbar(subset['Time'], subset['Whole_Total'], yerr=subset['Whole_SEM'], \n",
    "                    label=\"Whole\", linestyle='-', marker='o', color=colors[treatment][0])\n",
    "        ax.errorbar(subset['Time'], subset['Head_Total'], yerr=subset['Head_SEM'], \n",
    "                    label=\"Head\", linestyle='--', marker='x', color=colors[treatment][1])\n",
    "        ax.errorbar(subset['Time'], subset['Tail_Total'], yerr=subset['Tail_SEM'], \n",
    "                    label=\"Tail\", linestyle=':', marker='s', color=colors[treatment][2])\n",
    "\n",
    "        # Set titles and axis labels\n",
    "        ax.set_title(treatment)\n",
    "        ax.set_xlabel(\"Time [min]\")\n",
    "        ax.grid()\n",
    "\n",
    "        # Add legend for the subplot\n",
    "        ax.legend(title=\"Region\")\n",
    "\n",
    "    # Set shared y-axis label\n",
    "    axes[0].set_ylabel(\"Corrected Total GFP Intensity\")\n",
    "\n",
    "    # Add a shared title and adjust layout\n",
    "    fig.suptitle(\"Corrected Total GFP Intensity Over Time by Region and Treatment\", fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Plot the total GFP intensity results\n",
    "plot_total_gfp_intensity(summary_total, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_gfp_intensity(summary: pd.DataFrame, colors: dict):\n",
    "    \"\"\"\n",
    "    Plot corrected mean GFP intensities over time for all treatments and regions in a single line plot.\n",
    "\n",
    "    Args:\n",
    "        summary (pd.DataFrame): Summary DataFrame with mean GFP intensities for whole fish, head, and tail.\n",
    "        colors (dict): A dictionary mapping treatments to color palettes for plotting.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a combined line plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))  # Set figure size\n",
    "\n",
    "    for treatment in summary['Treatment'].unique():\n",
    "        subset = summary[summary['Treatment'] == treatment]\n",
    "        \n",
    "        # Plot Whole Mean Intensity\n",
    "        plt.plot(\n",
    "            subset['Time'], subset['Whole_Mean'], \n",
    "            label=f\"{treatment} - Whole\", linestyle='-', marker='o', color=colors[treatment][0]\n",
    "        )\n",
    "        # Plot Head Mean Intensity\n",
    "        plt.plot(\n",
    "            subset['Time'], subset['Head_Mean'], \n",
    "            label=f\"{treatment} - Head\", linestyle='--', marker='x', color=colors[treatment][1]\n",
    "        )\n",
    "        # Plot Tail Mean Intensity\n",
    "        plt.plot(\n",
    "            subset['Time'], subset['Tail_Mean'], \n",
    "            label=f\"{treatment} - Tail\", linestyle=':', marker='s', color=colors[treatment][2]\n",
    "        )\n",
    "\n",
    "    # Add axis labels and title\n",
    "    plt.xlabel(\"Time [min]\")\n",
    "    plt.ylabel(\"Corrected Mean GFP Intensity\")\n",
    "    plt.title(\"Comparison of Corrected Mean GFP Intensity Over Time (All Treatments & Regions)\")\n",
    "\n",
    "    # Add legend and grid\n",
    "    plt.legend(title=\"Treatment & Region\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the combined GFP intensity for all treatments and regions\n",
    "plot_combined_gfp_intensity(summary, colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_area(summary_total: pd.DataFrame, colors: dict, treatments: list):\n",
    "    \"\"\"\n",
    "    Create a stacked area plot showing corrected total GFP intensities for head, tail, and whole fish\n",
    "    over time for each treatment.\n",
    "\n",
    "    Args:\n",
    "        summary_total (pd.DataFrame): DataFrame containing total GFP intensities for whole fish, head, and tail.\n",
    "        colors (dict): A dictionary mapping treatments to color palettes for plotting.\n",
    "        treatments (list): List of treatments to plot.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a stacked area plot.\n",
    "    \"\"\"\n",
    "    # Set up the subplots\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "    for ax, treatment in zip(axes, treatments):\n",
    "        subset = summary_total[summary_total['Treatment'] == treatment]\n",
    "\n",
    "        # Ensure stacking order: Head + Tail + Whole\n",
    "        total_sum = subset['Head_Total'] + subset['Tail_Total']\n",
    "        \n",
    "        # Plot head region\n",
    "        ax.fill_between(\n",
    "            subset['Time'], 0, subset['Head_Total'], \n",
    "            color=colors[treatment][1], alpha=0.6, label=\"Head\"\n",
    "        )\n",
    "        \n",
    "        # Plot tail region\n",
    "        ax.fill_between(\n",
    "            subset['Time'], subset['Head_Total'], total_sum, \n",
    "            color=colors[treatment][2], alpha=0.6, label=\"Tail\"\n",
    "        )\n",
    "        \n",
    "        # Plot whole fish region\n",
    "        ax.fill_between(\n",
    "            subset['Time'], total_sum, total_sum + subset['Whole_Total'], \n",
    "            color=colors[treatment][0], alpha=0.6, label=\"Whole\"\n",
    "        )\n",
    "\n",
    "        # Add titles and grid\n",
    "        ax.set_title(treatment)\n",
    "        ax.set_xlabel(\"Time [min]\")\n",
    "        ax.grid()\n",
    "\n",
    "        # Add a legend for each subplot\n",
    "        ax.legend(title=\"Region\", loc=\"upper left\")\n",
    "\n",
    "    # Add shared y-axis label and a title for the plot\n",
    "    axes[0].set_ylabel(\"Corrected Total GFP Intensity\")\n",
    "    fig.suptitle(\"Stacked Area Plot of Corrected Total GFP Intensity by Region and Treatment\", fontsize=16)\n",
    "    \n",
    "    # Adjust layout and display the plot\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Plot the stacked area chart for total GFP intensities\n",
    "plot_stacked_area(summary_total, colors, treatments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalized_gfp_heatmaps(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Generates heatmaps for normalized corrected mean GFP intensities (whole fish, head, and tail)\n",
    "    over time for each treatment.\n",
    "\n",
    "    Steps:\n",
    "    1. Normalizes the corrected mean GFP intensity for each region within each treatment.\n",
    "    2. Creates heatmaps for normalized intensities for the whole fish, head, and tail.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing corrected GFP intensity values for whole fish, head, and tail.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the heatmaps.\n",
    "    \"\"\"\n",
    "    # --- Normalize intensities within each region ---\n",
    "    df['Normalized_Whole_Mean'] = df.groupby('Treatment')['Corrected_Mean_GFP_Intensity'].transform(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "    )\n",
    "    df['Normalized_Head_Mean'] = df.groupby('Treatment')['Corrected_Mean_Head_Intensity'].transform(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "    )\n",
    "    df['Normalized_Tail_Mean'] = df.groupby('Treatment')['Corrected_Mean_Tail_Intensity'].transform(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "    )\n",
    "\n",
    "    # --- Heatmap for normalized whole fish GFP intensities ---\n",
    "    heatmap_data = df.pivot_table(\n",
    "        index='Treatment', columns='Time', values='Normalized_Whole_Mean', aggfunc='mean'\n",
    "    )\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(heatmap_data, cmap='viridis', annot=False)\n",
    "    plt.title(\"Heatmap of Normalized Corrected Mean GFP Intensity (Whole Fish)\")\n",
    "    plt.xlabel(\"Time [min]\")\n",
    "    plt.ylabel(\"Treatment\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- Separate heatmaps for head and tail regions ---\n",
    "    for region, column in [('Head', 'Normalized_Head_Mean'), ('Tail', 'Normalized_Tail_Mean')]:\n",
    "        heatmap_data = df.pivot_table(\n",
    "            index='Treatment', columns='Time', values=column, aggfunc='mean'\n",
    "        )\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(heatmap_data, cmap='viridis', annot=False)\n",
    "        plt.title(f\"Heatmap of Normalized Corrected Mean GFP Intensity ({region})\")\n",
    "        plt.xlabel(\"Time [min]\")\n",
    "        plt.ylabel(\"Treatment\")\n",
    "        plt.show()\n",
    "\n",
    "# Call the function to generate heatmaps\n",
    "plot_normalized_gfp_heatmaps(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MoIm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
