{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dave-\\anaconda3\\envs\\MoIm\\Lib\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "# Define the SAM model outside of multiprocessing functions to avoid reloading it each time\n",
    "model_type = \"vit_h\"\n",
    "sam = sam_model_registry[model_type](checkpoint=\"./sam_vit_h_4b8939.pth\")\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for loading and saving images\n",
    "input_dir = r\"C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\test_images\"\n",
    "output_dir = r\"C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\Output_test_images\"\n",
    "phase_mask_dir = os.path.join(output_dir, \"phase_masks\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier(filename: str) -> str:\n",
    "    \"\"\"Extracts a unique identifier from a filename.\"\"\"\n",
    "    match = re.match(r\"^([A-D]\\d+_\\d+).*_(\\d{3})\\.tif$\", filename)\n",
    "    return f\"{match.group(1)}_{match.group(2)}\" if match else None\n",
    "\n",
    "def process_image_pair(identifier: str, phase_file: str, gfp_file: str, input_dir: str, output_dir: str, \n",
    "                       save_masks: bool = False, save_masked_images: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Processes a pair of 'Phase Contrast' and 'GFP' images, generates a binary mask using SAM, \n",
    "    calculates GFP intensity within the mask, and optionally saves the mask and masked images.\n",
    "    \n",
    "    Args:\n",
    "        identifier (str): Unique identifier for the image pair.\n",
    "        phase_file (str): Filename of the Phase Contrast image.\n",
    "        gfp_file (str): Filename of the GFP image.\n",
    "        input_dir (str): Directory containing the input images.\n",
    "        output_dir (str): Directory to save the output files.\n",
    "        save_masks (bool): If True, saves generated masks as PNG files.\n",
    "        save_masked_images (bool): If True, saves masked GFP images.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing the identifier, mean GFP intensity, and total GFP intensity.\n",
    "    \"\"\"\n",
    "    # Initialize SAM model in each process\n",
    "    model_type = \"vit_h\"  # Model type can be \"vit_h\", \"vit_l\", or \"vit_b\"\n",
    "    sam = sam_model_registry[model_type](checkpoint=\"./sam_vit_h_4b8939.pth\")\n",
    "    predictor = SamPredictor(sam)\n",
    "\n",
    "    phase_mask_dir = os.path.join(output_dir, \"phase_masks\")\n",
    "    if save_masks:\n",
    "        os.makedirs(phase_mask_dir, exist_ok=True)\n",
    "        \n",
    "    # Load and process the Phase Contrast image\n",
    "    phase_path = os.path.join(input_dir, phase_file)\n",
    "    phase_image = Image.open(phase_path)\n",
    "    phase_np = np.array(phase_image, dtype=np.uint16)\n",
    "    phase_np = (phase_np / phase_np.max() * 255).astype(np.uint8)\n",
    "    phase_rgb = np.stack([phase_np] * 3, axis=-1)\n",
    "\n",
    "    # Set the image in SAM model for mask generation\n",
    "    predictor.set_image(phase_rgb)\n",
    "    input_point = np.array([[phase_rgb.shape[1] // 2, phase_rgb.shape[0] // 2]])\n",
    "    input_label = np.array([1])\n",
    "\n",
    "    # Generate mask\n",
    "    masks, scores, _ = predictor.predict(\n",
    "        point_coords=input_point,\n",
    "        point_labels=input_label,\n",
    "        multimask_output=False\n",
    "    )\n",
    "    mask = masks[0]\n",
    "\n",
    "    # Optionally save the generated mask\n",
    "    if save_masks:\n",
    "        mask_output_path = os.path.join(phase_mask_dir, f\"mask_{os.path.splitext(phase_file)[0]}.png\")\n",
    "        Image.fromarray((mask * 255).astype(np.uint8)).save(mask_output_path)\n",
    "\n",
    "    # Load and process the GFP image\n",
    "    gfp_path = os.path.join(input_dir, gfp_file)\n",
    "    gfp_image = Image.open(gfp_path)\n",
    "    gfp_np = np.array(gfp_image, dtype=np.uint16)\n",
    "\n",
    "    # Calculate GFP intensities\n",
    "    gfp_values_within_fish = gfp_np[mask > 0]\n",
    "    mean_gfp_intensity = gfp_values_within_fish.mean() if gfp_values_within_fish.size > 0 else 0\n",
    "    total_gfp_intensity = gfp_values_within_fish.sum()\n",
    "\n",
    "    # Optionally save the masked GFP image\n",
    "    if save_masked_images:\n",
    "        gfp_masked = gfp_np * mask\n",
    "        output_path = os.path.join(output_dir, f\"masked_{gfp_file}\")\n",
    "        Image.fromarray(gfp_masked.astype(np.uint16)).save(output_path)\n",
    "\n",
    "    return {\n",
    "        \"Identifier\": identifier,\n",
    "        \"Mean_GFP_Intensity\": mean_gfp_intensity,\n",
    "        \"Total_GFP_Intensity\": total_gfp_intensity\n",
    "    }\n",
    "\n",
    "def collect_image_pairs(input_dir: str):\n",
    "    \"\"\"\n",
    "    Collects and pairs 'Phase Contrast' and 'GFP' image files based on a unique identifier.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Directory containing the input images.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains an identifier and the filenames for Phase Contrast and GFP images.\n",
    "    \"\"\"\n",
    "    phase_contrast_files = {}\n",
    "    gfp_files = {}\n",
    "\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith(\".tif\"):\n",
    "            identifier = get_identifier(file_name)\n",
    "            if identifier:\n",
    "                if \"Phase Contrast\" in file_name:\n",
    "                    phase_contrast_files[identifier] = file_name\n",
    "                elif \"GFP\" in file_name:\n",
    "                    gfp_files[identifier] = file_name\n",
    "\n",
    "    image_pairs = [\n",
    "        (identifier, phase_contrast_files[identifier], gfp_files[identifier])\n",
    "        for identifier in phase_contrast_files if identifier in gfp_files\n",
    "    ]\n",
    "    return image_pairs\n",
    "\n",
    "def process_images(input_dir: str, output_dir: str, save_masks: bool = False, save_masked_images: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uses multiprocessing to process all image pairs in parallel, generating masks, calculating GFP intensities, \n",
    "    and optionally saving the outputs.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Directory containing the input images.\n",
    "        output_dir (str): Directory to save the output files.\n",
    "        save_masks (bool): If True, saves the generated masks as PNG files.\n",
    "        save_masked_images (bool): If True, saves the masked GFP images.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing GFP intensity data (mean and total) for each image pair.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Collect all Phase Contrast and GFP image pairs\n",
    "    image_pairs = collect_image_pairs(input_dir)\n",
    "    results = []\n",
    "\n",
    "    # Use ProcessPoolExecutor for parallel processing\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                process_image_pair, identifier, phase_file, gfp_file, input_dir, output_dir, save_masks, save_masked_images\n",
    "            )\n",
    "            for identifier, phase_file, gfp_file in image_pairs\n",
    "        ]\n",
    "\n",
    "        # Collect results as tasks complete\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing an image pair: {e}\")\n",
    "\n",
    "    # Convert results to a DataFrame and save as CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    csv_output_path = os.path.join(output_dir, \"gfp_intensity_results.csv\")\n",
    "    results_df.to_csv(csv_output_path, index=False)\n",
    "    \n",
    "    print(f\"Results saved to {csv_output_path}\")\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing an image pair: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing an image pair: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing an image pair: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing an image pair: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Results saved to C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\Output_test_images\\gfp_intensity_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the parallelized image processing function\n",
    "gfp_intensity_results_df = process_images(input_dir, output_dir, save_masks=True, save_masked_images=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MoIm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
