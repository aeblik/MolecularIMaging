{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Daten\\MolecularIMaging\\molecularimaging\\lib\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "# Load SAM Model\n",
    "model_type = \"vit_l\"  # Model type can be \"vit_h\", \"vit_l\", or \"vit_b\"\n",
    "#sam = sam_model_registry[model_type](checkpoint=\"./sam_vit_h_4b8939.pth\")\n",
    "sam = sam_model_registry[model_type](checkpoint=\"./sam_vit_l_0b3195.pth\")\n",
    "#sam = sam_model_registry[model_type](checkpoint=\"./sam_vit_b_01ec64.pth\")\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts a unique identifier from a filename using a regular expression pattern.\n",
    "    \"\"\"\n",
    "    match = re.match(r\"^([A-D]\\d+_\\d+).*_(\\d{3})\\.tif$\", filename)\n",
    "    return f\"{match.group(1)}_{match.group(2)}\" if match else None\n",
    "\n",
    "def split_mask(mask: np.array) -> tuple:\n",
    "    \"\"\"\n",
    "    Splits a mask into two regions: head (first one-third) and tail (remaining two-thirds).\n",
    "    \"\"\"\n",
    "    split_index = mask.shape[1] // 3  # Compute the index for one-third of the image width\n",
    "\n",
    "    head_mask = np.zeros_like(mask)  # Mask for the head (first one-third)\n",
    "    tail_mask = np.zeros_like(mask)  # Mask for the tail (remaining two-thirds)\n",
    "\n",
    "    head_mask[:, :split_index] = mask[:, :split_index]  # First one-third (head)\n",
    "    tail_mask[:, split_index:] = mask[:, split_index:]  # Remaining two-thirds (tail)\n",
    "\n",
    "    return head_mask, tail_mask\n",
    "\n",
    "def process_images(input_dir: str, output_dir: str, \n",
    "                   save_masks: bool = True, save_masked_images: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes pairs of 'Phase Contrast' and 'GFP' images to generate a binary mask using SAM, \n",
    "    calculate GFP intensity within the mask, and save mask and masked images for head, tail, and whole fish.\n",
    "    \"\"\"\n",
    "    # Create subdirectories for saving masks and masked images\n",
    "    phase_mask_dir = os.path.join(output_dir, \"phase_masks\")\n",
    "    head_mask_dir = os.path.join(output_dir, \"head_masks\")\n",
    "    tail_mask_dir = os.path.join(output_dir, \"tail_masks\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if save_masks:\n",
    "        os.makedirs(phase_mask_dir, exist_ok=True)\n",
    "        os.makedirs(head_mask_dir, exist_ok=True)\n",
    "        os.makedirs(tail_mask_dir, exist_ok=True)\n",
    "\n",
    "    phase_contrast_files = {}\n",
    "    gfp_files = {}\n",
    "\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith(\".tif\"):\n",
    "            identifier = get_identifier(file_name)\n",
    "            if identifier:\n",
    "                if \"Phase Contrast\" in file_name:\n",
    "                    phase_contrast_files[identifier] = file_name\n",
    "                elif \"GFP\" in file_name:\n",
    "                    gfp_files[identifier] = file_name\n",
    "\n",
    "    gfp_intensity_results = []\n",
    "\n",
    "    for i, (identifier, phase_file) in enumerate(phase_contrast_files.items()):\n",
    "        if identifier in gfp_files:\n",
    "            try:\n",
    "                phase_path = os.path.join(input_dir, phase_file)\n",
    "                gfp_path = os.path.join(input_dir, gfp_files[identifier])\n",
    "                \n",
    "                # Load Phase Contrast image\n",
    "                phase_image = Image.open(phase_path)\n",
    "                phase_np = np.array(phase_image, dtype=np.uint16)\n",
    "                phase_np = (phase_np / phase_np.max() * 255).astype(np.uint8)\n",
    "                phase_rgb = np.stack([phase_np] * 3, axis=-1)\n",
    "\n",
    "                predictor.set_image(phase_rgb)\n",
    "\n",
    "                # Generate primary mask\n",
    "                input_point = np.array([[phase_rgb.shape[1] // 2, phase_rgb.shape[0] // 2]])\n",
    "                input_label = np.array([1])\n",
    "                masks, scores, _ = predictor.predict(\n",
    "                    point_coords=input_point,\n",
    "                    point_labels=input_label,\n",
    "                    multimask_output=False\n",
    "                )\n",
    "                primary_mask = masks[0]\n",
    "\n",
    "                # Save whole fish mask\n",
    "                if save_masks:\n",
    "                    mask_output_path = os.path.join(phase_mask_dir, f\"mask_{os.path.splitext(phase_file)[0]}.png\")\n",
    "                    Image.fromarray((primary_mask * 255).astype(np.uint8)).save(mask_output_path)\n",
    "\n",
    "                # Split mask into head and tail\n",
    "                head_mask, tail_mask = split_mask(primary_mask)\n",
    "\n",
    "                # Save head and tail masks\n",
    "                if save_masks:\n",
    "                    head_mask_output_path = os.path.join(head_mask_dir, f\"head_mask_{os.path.splitext(phase_file)[0]}.png\")\n",
    "                    tail_mask_output_path = os.path.join(tail_mask_dir, f\"tail_mask_{os.path.splitext(phase_file)[0]}.png\")\n",
    "                    Image.fromarray((head_mask * 255).astype(np.uint8)).save(head_mask_output_path)\n",
    "                    Image.fromarray((tail_mask * 255).astype(np.uint8)).save(tail_mask_output_path)\n",
    "\n",
    "                # Load GFP image\n",
    "                gfp_image = Image.open(gfp_path)\n",
    "                gfp_np = np.array(gfp_image, dtype=np.uint16)\n",
    "\n",
    "                # Calculate GFP intensities for whole fish, head, and tail\n",
    "                gfp_values_within_fish = gfp_np[primary_mask > 0]\n",
    "                mean_gfp_intensity = gfp_values_within_fish.mean() if gfp_values_within_fish.size > 0 else 0\n",
    "                total_gfp_intensity = gfp_values_within_fish.sum()\n",
    "\n",
    "                gfp_values_within_head = gfp_np[head_mask > 0]\n",
    "                mean_gfp_head = gfp_values_within_head.mean() if gfp_values_within_head.size > 0 else 0\n",
    "                total_gfp_head = gfp_values_within_head.sum()\n",
    "\n",
    "                gfp_values_within_tail = gfp_np[tail_mask > 0]\n",
    "                mean_gfp_tail = gfp_values_within_tail.mean() if gfp_values_within_tail.size > 0 else 0\n",
    "                total_gfp_tail = gfp_values_within_tail.sum()\n",
    "\n",
    "                # Save masked GFP images\n",
    "                if save_masked_images:\n",
    "                    gfp_masked = gfp_np * primary_mask\n",
    "                    head_masked = gfp_np * head_mask\n",
    "                    tail_masked = gfp_np * tail_mask\n",
    "\n",
    "                    gfp_output_path = os.path.join(output_dir, f\"masked_{identifier}.png\")\n",
    "                    head_output_path = os.path.join(output_dir, f\"masked_head_{identifier}.png\")\n",
    "                    tail_output_path = os.path.join(output_dir, f\"masked_tail_{identifier}.png\")\n",
    "\n",
    "                    Image.fromarray(gfp_masked.astype(np.uint16)).save(gfp_output_path)\n",
    "                    Image.fromarray(head_masked.astype(np.uint16)).save(head_output_path)\n",
    "                    Image.fromarray(tail_masked.astype(np.uint16)).save(tail_output_path)\n",
    "\n",
    "                # Append GFP intensity results\n",
    "                gfp_intensity_results.append({\n",
    "                    \"Identifier\": identifier,\n",
    "                    \"Mean_GFP_Intensity\": mean_gfp_intensity,\n",
    "                    \"Total_GFP_Intensity\": total_gfp_intensity,\n",
    "                    \"Mean_GFP_Head\": mean_gfp_head,\n",
    "                    \"Total_GFP_Head\": total_gfp_head,\n",
    "                    \"Mean_GFP_Tail\": mean_gfp_tail,\n",
    "                    \"Total_GFP_Tail\": total_gfp_tail\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {identifier}: {e}\")\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(phase_contrast_files)} image pairs.\")\n",
    "\n",
    "    results_df = pd.DataFrame(gfp_intensity_results)\n",
    "    csv_output_path = os.path.join(output_dir, \"gfp_intensity_results_vit_l.csv\")\n",
    "    results_df.to_csv(csv_output_path, index=False)\n",
    "    \n",
    "    print(f\"Results saved to {csv_output_path}\") \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "input_dir = r\"C:\\Daten\\MoIm\\Images\"\n",
    "output_dir = r\"C:\\Daten\\MoIm\\Output\\Model_L\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5/1281 image pairs.\n",
      "Processed 10/1281 image pairs.\n",
      "Processed 15/1281 image pairs.\n",
      "Processed 20/1281 image pairs.\n",
      "Processed 25/1281 image pairs.\n",
      "Processed 30/1281 image pairs.\n",
      "Processed 35/1281 image pairs.\n",
      "Processed 40/1281 image pairs.\n",
      "Processed 45/1281 image pairs.\n",
      "Processed 50/1281 image pairs.\n",
      "Processed 55/1281 image pairs.\n",
      "Processed 60/1281 image pairs.\n",
      "Processed 65/1281 image pairs.\n",
      "Processed 70/1281 image pairs.\n",
      "Processed 75/1281 image pairs.\n",
      "Processed 80/1281 image pairs.\n",
      "Processed 85/1281 image pairs.\n",
      "Processed 90/1281 image pairs.\n",
      "Processed 95/1281 image pairs.\n",
      "Processed 100/1281 image pairs.\n",
      "Processed 105/1281 image pairs.\n",
      "Processed 110/1281 image pairs.\n",
      "Processed 115/1281 image pairs.\n",
      "Processed 120/1281 image pairs.\n",
      "Processed 125/1281 image pairs.\n",
      "Processed 130/1281 image pairs.\n",
      "Processed 135/1281 image pairs.\n",
      "Processed 140/1281 image pairs.\n",
      "Processed 145/1281 image pairs.\n",
      "Processed 150/1281 image pairs.\n",
      "Processed 155/1281 image pairs.\n",
      "Processed 160/1281 image pairs.\n",
      "Processed 165/1281 image pairs.\n",
      "Processed 170/1281 image pairs.\n",
      "Processed 175/1281 image pairs.\n",
      "Processed 180/1281 image pairs.\n",
      "Processed 185/1281 image pairs.\n",
      "Processed 190/1281 image pairs.\n",
      "Processed 195/1281 image pairs.\n",
      "Processed 200/1281 image pairs.\n",
      "Processed 205/1281 image pairs.\n",
      "Processed 210/1281 image pairs.\n",
      "Processed 215/1281 image pairs.\n",
      "Processed 220/1281 image pairs.\n",
      "Processed 225/1281 image pairs.\n",
      "Processed 230/1281 image pairs.\n",
      "Processed 235/1281 image pairs.\n",
      "Processed 240/1281 image pairs.\n",
      "Processed 245/1281 image pairs.\n",
      "Processed 250/1281 image pairs.\n",
      "Processed 255/1281 image pairs.\n",
      "Processed 260/1281 image pairs.\n",
      "Processed 265/1281 image pairs.\n",
      "Processed 270/1281 image pairs.\n",
      "Processed 275/1281 image pairs.\n",
      "Processed 280/1281 image pairs.\n",
      "Processed 285/1281 image pairs.\n",
      "Processed 290/1281 image pairs.\n",
      "Processed 295/1281 image pairs.\n",
      "Processed 300/1281 image pairs.\n",
      "Processed 305/1281 image pairs.\n",
      "Processed 310/1281 image pairs.\n",
      "Processed 315/1281 image pairs.\n",
      "Processed 320/1281 image pairs.\n",
      "Processed 325/1281 image pairs.\n",
      "Processed 330/1281 image pairs.\n",
      "Processed 335/1281 image pairs.\n",
      "Processed 340/1281 image pairs.\n",
      "Processed 345/1281 image pairs.\n",
      "Processed 350/1281 image pairs.\n",
      "Processed 355/1281 image pairs.\n",
      "Processed 360/1281 image pairs.\n",
      "Processed 365/1281 image pairs.\n",
      "Processed 370/1281 image pairs.\n",
      "Processed 375/1281 image pairs.\n",
      "Processed 380/1281 image pairs.\n",
      "Processed 385/1281 image pairs.\n",
      "Processed 390/1281 image pairs.\n",
      "Processed 395/1281 image pairs.\n",
      "Processed 400/1281 image pairs.\n",
      "Processed 405/1281 image pairs.\n",
      "Processed 410/1281 image pairs.\n",
      "Processed 415/1281 image pairs.\n",
      "Processed 420/1281 image pairs.\n",
      "Processed 425/1281 image pairs.\n",
      "Processed 430/1281 image pairs.\n",
      "Processed 435/1281 image pairs.\n",
      "Processed 440/1281 image pairs.\n",
      "Processed 445/1281 image pairs.\n",
      "Processed 450/1281 image pairs.\n",
      "Processed 455/1281 image pairs.\n",
      "Processed 460/1281 image pairs.\n",
      "Processed 465/1281 image pairs.\n",
      "Processed 470/1281 image pairs.\n",
      "Processed 475/1281 image pairs.\n",
      "Processed 480/1281 image pairs.\n",
      "Processed 485/1281 image pairs.\n",
      "Processed 490/1281 image pairs.\n",
      "Processed 495/1281 image pairs.\n",
      "Processed 500/1281 image pairs.\n",
      "Processed 505/1281 image pairs.\n",
      "Processed 510/1281 image pairs.\n",
      "Processed 515/1281 image pairs.\n",
      "Processed 520/1281 image pairs.\n",
      "Processed 525/1281 image pairs.\n",
      "Processed 530/1281 image pairs.\n",
      "Processed 535/1281 image pairs.\n",
      "Processed 540/1281 image pairs.\n",
      "Processed 545/1281 image pairs.\n",
      "Processed 550/1281 image pairs.\n",
      "Processed 555/1281 image pairs.\n",
      "Processed 560/1281 image pairs.\n",
      "Processed 565/1281 image pairs.\n",
      "Processed 570/1281 image pairs.\n",
      "Processed 575/1281 image pairs.\n",
      "Processed 580/1281 image pairs.\n",
      "Processed 585/1281 image pairs.\n",
      "Processed 590/1281 image pairs.\n",
      "Processed 595/1281 image pairs.\n",
      "Processed 600/1281 image pairs.\n",
      "Processed 605/1281 image pairs.\n",
      "Processed 610/1281 image pairs.\n",
      "Processed 615/1281 image pairs.\n",
      "Processed 620/1281 image pairs.\n",
      "Processed 625/1281 image pairs.\n",
      "Processed 630/1281 image pairs.\n",
      "Processed 635/1281 image pairs.\n",
      "Processed 640/1281 image pairs.\n",
      "Processed 645/1281 image pairs.\n",
      "Processed 650/1281 image pairs.\n",
      "Processed 655/1281 image pairs.\n",
      "Processed 660/1281 image pairs.\n",
      "Processed 665/1281 image pairs.\n",
      "Processed 670/1281 image pairs.\n",
      "Processed 675/1281 image pairs.\n",
      "Processed 680/1281 image pairs.\n",
      "Processed 685/1281 image pairs.\n",
      "Processed 690/1281 image pairs.\n",
      "Processed 695/1281 image pairs.\n",
      "Processed 700/1281 image pairs.\n",
      "Processed 705/1281 image pairs.\n",
      "Processed 710/1281 image pairs.\n",
      "Processed 715/1281 image pairs.\n",
      "Processed 720/1281 image pairs.\n",
      "Processed 725/1281 image pairs.\n",
      "Processed 730/1281 image pairs.\n",
      "Processed 735/1281 image pairs.\n",
      "Processed 740/1281 image pairs.\n",
      "Processed 745/1281 image pairs.\n",
      "Processed 750/1281 image pairs.\n",
      "Processed 755/1281 image pairs.\n",
      "Processed 760/1281 image pairs.\n",
      "Processed 765/1281 image pairs.\n",
      "Processed 770/1281 image pairs.\n",
      "Processed 775/1281 image pairs.\n",
      "Processed 780/1281 image pairs.\n",
      "Processed 785/1281 image pairs.\n",
      "Processed 790/1281 image pairs.\n",
      "Processed 795/1281 image pairs.\n",
      "Processed 800/1281 image pairs.\n",
      "Processed 805/1281 image pairs.\n",
      "Processed 810/1281 image pairs.\n",
      "Processed 815/1281 image pairs.\n",
      "Processed 820/1281 image pairs.\n",
      "Processed 825/1281 image pairs.\n",
      "Processed 830/1281 image pairs.\n",
      "Processed 835/1281 image pairs.\n",
      "Processed 840/1281 image pairs.\n",
      "Processed 845/1281 image pairs.\n",
      "Processed 850/1281 image pairs.\n",
      "Processed 855/1281 image pairs.\n",
      "Processed 860/1281 image pairs.\n",
      "Processed 865/1281 image pairs.\n",
      "Processed 870/1281 image pairs.\n",
      "Processed 875/1281 image pairs.\n",
      "Processed 880/1281 image pairs.\n",
      "Processed 885/1281 image pairs.\n",
      "Processed 890/1281 image pairs.\n",
      "Processed 895/1281 image pairs.\n",
      "Processed 900/1281 image pairs.\n",
      "Processed 905/1281 image pairs.\n",
      "Processed 910/1281 image pairs.\n",
      "Processed 915/1281 image pairs.\n",
      "Processed 920/1281 image pairs.\n",
      "Processed 925/1281 image pairs.\n",
      "Processed 930/1281 image pairs.\n",
      "Processed 935/1281 image pairs.\n",
      "Processed 940/1281 image pairs.\n",
      "Processed 945/1281 image pairs.\n",
      "Processed 950/1281 image pairs.\n",
      "Processed 955/1281 image pairs.\n",
      "Processed 960/1281 image pairs.\n",
      "Processed 965/1281 image pairs.\n",
      "Processed 970/1281 image pairs.\n",
      "Processed 975/1281 image pairs.\n",
      "Processed 980/1281 image pairs.\n",
      "Processed 985/1281 image pairs.\n",
      "Processed 990/1281 image pairs.\n",
      "Processed 995/1281 image pairs.\n",
      "Processed 1000/1281 image pairs.\n",
      "Processed 1005/1281 image pairs.\n",
      "Processed 1010/1281 image pairs.\n",
      "Processed 1015/1281 image pairs.\n",
      "Processed 1020/1281 image pairs.\n",
      "Processed 1025/1281 image pairs.\n",
      "Processed 1030/1281 image pairs.\n",
      "Processed 1035/1281 image pairs.\n",
      "Processed 1040/1281 image pairs.\n",
      "Processed 1045/1281 image pairs.\n",
      "Processed 1050/1281 image pairs.\n",
      "Processed 1055/1281 image pairs.\n",
      "Processed 1060/1281 image pairs.\n",
      "Processed 1065/1281 image pairs.\n",
      "Processed 1070/1281 image pairs.\n",
      "Processed 1075/1281 image pairs.\n",
      "Processed 1080/1281 image pairs.\n",
      "Processed 1085/1281 image pairs.\n",
      "Processed 1090/1281 image pairs.\n",
      "Processed 1095/1281 image pairs.\n",
      "Processed 1100/1281 image pairs.\n",
      "Processed 1105/1281 image pairs.\n",
      "Processed 1110/1281 image pairs.\n",
      "Processed 1115/1281 image pairs.\n",
      "Processed 1120/1281 image pairs.\n",
      "Processed 1125/1281 image pairs.\n",
      "Processed 1130/1281 image pairs.\n",
      "Processed 1135/1281 image pairs.\n",
      "Processed 1140/1281 image pairs.\n",
      "Processed 1145/1281 image pairs.\n",
      "Processed 1150/1281 image pairs.\n",
      "Processed 1155/1281 image pairs.\n",
      "Processed 1160/1281 image pairs.\n",
      "Processed 1165/1281 image pairs.\n",
      "Processed 1170/1281 image pairs.\n",
      "Processed 1175/1281 image pairs.\n",
      "Processed 1180/1281 image pairs.\n",
      "Processed 1185/1281 image pairs.\n",
      "Processed 1190/1281 image pairs.\n",
      "Processed 1195/1281 image pairs.\n",
      "Processed 1200/1281 image pairs.\n",
      "Processed 1205/1281 image pairs.\n",
      "Processed 1210/1281 image pairs.\n",
      "Processed 1215/1281 image pairs.\n",
      "Processed 1220/1281 image pairs.\n",
      "Processed 1225/1281 image pairs.\n",
      "Processed 1230/1281 image pairs.\n",
      "Processed 1235/1281 image pairs.\n",
      "Processed 1240/1281 image pairs.\n",
      "Processed 1245/1281 image pairs.\n",
      "Processed 1250/1281 image pairs.\n",
      "Processed 1255/1281 image pairs.\n",
      "Processed 1260/1281 image pairs.\n",
      "Processed 1265/1281 image pairs.\n",
      "Processed 1270/1281 image pairs.\n",
      "Processed 1275/1281 image pairs.\n",
      "Processed 1280/1281 image pairs.\n",
      "Results saved to C:\\Daten\\MoIm\\Output\\Model_L\\gfp_intensity_results_vit_l.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the function\n",
    "gfp_intensity_results_df = process_images(input_dir, output_dir, save_masks=True, save_masked_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtimes for 8 image pairs\n",
    "Base model: 1min 3.5s (imperfect masks)\n",
    "\n",
    "Large model: 2min 35.9s (perfect masks)\n",
    "\n",
    "Huge model: 4min 53s (perfect masks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molecularimaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
