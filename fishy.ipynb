{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dave-\\anaconda3\\envs\\MoIm\\Lib\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "# Load SAM Model\n",
    "model_type = \"vit_h\"  # Model type can be \"vit_h\", \"vit_l\", or \"vit_b\"\n",
    "sam = sam_model_registry[model_type](checkpoint=\"./sam_vit_h_4b8939.pth\")\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts a unique identifier from a filename using a regular expression pattern.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): The filename of the image (e.g., 'A1_03_1_1_Phase Contrast_001.tif').\n",
    "    \n",
    "    Returns:\n",
    "        str: A unique identifier based on the first two parts and last three digits of the filename.\n",
    "             If the filename does not match the expected pattern, returns None.\n",
    "    \n",
    "    Example:\n",
    "        For a filename \"A1_03_1_1_Phase Contrast_001.tif\", the function returns \"A1_03_001\".\n",
    "    \"\"\"\n",
    "    match = re.match(r\"^([A-D]\\d+_\\d+).*_(\\d{3})\\.tif$\", filename)\n",
    "    return f\"{match.group(1)}_{match.group(2)}\" if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(input_dir: str, output_dir: str, \n",
    "                   save_masks: bool = False, save_masked_images: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes pairs of 'Phase Contrast' and 'GFP' images to generate a binary mask using SAM, \n",
    "    calculate GFP intensity within the mask, and optionally save mask and masked images.\n",
    "\n",
    "    Steps:\n",
    "    1. Matches pairs of 'Phase Contrast' and 'GFP' images based on unique identifiers.\n",
    "    2. Uses SAM (Segment Anything Model) to create a binary mask of the zebrafish in the 'Phase Contrast' image.\n",
    "    3. Calculates the mean and total GFP intensity within the masked zebrafish region in the corresponding GFP image.\n",
    "    4. Saves the results to a DataFrame and optionally outputs masks and masked GFP images.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Directory containing the input TIF images.\n",
    "        output_dir (str): Directory to save output files (e.g., masks and results).\n",
    "        save_masks (bool): If True, saves generated masks as PNG files for visual confirmation.\n",
    "        save_masked_images (bool): If True, saves the masked GFP images to output directory.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing GFP intensity data (mean and total) for each image pair.\n",
    "    \n",
    "    Example:\n",
    "        process_images(\"input_directory\", \"output_directory\", save_masks=True, save_masked_images=True)\n",
    "    \"\"\"\n",
    "    # Create a subdirectory for phase masks if saving masks is enabled\n",
    "    phase_mask_dir = os.path.join(output_dir, \"phase_masks\")\n",
    "    if save_masks:\n",
    "        os.makedirs(phase_mask_dir, exist_ok=True)\n",
    "\n",
    "    # Collect Phase Contrast and GFP image files into dictionaries by unique identifier\n",
    "    phase_contrast_files = {}  # Stores 'Phase Contrast' image paths by identifier\n",
    "    gfp_files = {}             # Stores 'GFP' image paths by identifier\n",
    "    \n",
    "    # Loop through files in the input directory to identify and categorize images\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith(\".tif\"):  # Only process .tif files\n",
    "            identifier = get_identifier(file_name)  # Get unique identifier for pairing\n",
    "            if identifier:\n",
    "                if \"Phase Contrast\" in file_name:\n",
    "                    phase_contrast_files[identifier] = file_name\n",
    "                elif \"GFP\" in file_name:\n",
    "                    gfp_files[identifier] = file_name\n",
    "\n",
    "    # List to store calculated GFP intensity results for each identifier\n",
    "    gfp_intensity_results = []\n",
    "\n",
    "    # Loop through each identifier and process the image pairs\n",
    "    for i, (identifier, phase_file) in enumerate(phase_contrast_files.items()):\n",
    "        if identifier in gfp_files:  # Only process if both Phase Contrast and GFP images exist\n",
    "            try:\n",
    "                # Construct full file paths for Phase Contrast and GFP images\n",
    "                phase_path = os.path.join(input_dir, phase_file)\n",
    "                gfp_path = os.path.join(input_dir, gfp_files[identifier])\n",
    "                \n",
    "                # Load Phase Contrast image and convert to numpy array\n",
    "                phase_image = Image.open(phase_path)\n",
    "                phase_np = np.array(phase_image, dtype=np.uint16)  # Preserve original data type\n",
    "\n",
    "                # Normalize Phase Contrast image to uint8 range for compatibility with SAM\n",
    "                phase_np = (phase_np / phase_np.max() * 255).astype(np.uint8)\n",
    "                phase_rgb = np.stack([phase_np] * 3, axis=-1)  # Convert grayscale to RGB\n",
    "\n",
    "                # Set the normalized RGB image in SAM model to generate the mask\n",
    "                predictor.set_image(phase_rgb)\n",
    "\n",
    "                # Define a point at the center of the image for SAM mask generation\n",
    "                input_point = np.array([[phase_rgb.shape[1] // 2, phase_rgb.shape[0] // 2]])\n",
    "                input_label = np.array([1])  # Label '1' indicates foreground\n",
    "\n",
    "                # Generate mask from SAM based on the central point input\n",
    "                masks, scores, _ = predictor.predict(\n",
    "                    point_coords=input_point,\n",
    "                    point_labels=input_label,\n",
    "                    multimask_output=False\n",
    "                )\n",
    "                mask = masks[0]  # Retrieve the primary mask from SAM's output\n",
    "\n",
    "                # Save the mask as a PNG if save_masks is True\n",
    "                if save_masks:\n",
    "                    mask_output_path = os.path.join(phase_mask_dir, f\"mask_{os.path.splitext(phase_file)[0]}.png\")\n",
    "                    Image.fromarray((mask * 255).astype(np.uint8)).save(mask_output_path)\n",
    "\n",
    "                # Load GFP image and convert to numpy array\n",
    "                gfp_image = Image.open(gfp_path)\n",
    "                gfp_np = np.array(gfp_image, dtype=np.uint16)  # Keep original data type for intensity accuracy\n",
    "\n",
    "                # Apply the mask to the GFP image to isolate the region within the fish\n",
    "                gfp_values_within_fish = gfp_np[mask > 0]  # Masked GFP intensity values\n",
    "                mean_gfp_intensity = gfp_values_within_fish.mean() if gfp_values_within_fish.size > 0 else 0\n",
    "                total_gfp_intensity = gfp_values_within_fish.sum()\n",
    "\n",
    "                # Save the masked GFP image if save_masked_images is True\n",
    "                if save_masked_images:\n",
    "                    gfp_masked = gfp_np * mask  # Apply mask to the GFP image array\n",
    "                    output_path = os.path.join(output_dir, f\"masked_{gfp_files[identifier]}.png\")\n",
    "                    Image.fromarray(gfp_masked.astype(np.uint16)).save(output_path)\n",
    "\n",
    "                # Append the calculated GFP intensities to the results list\n",
    "                gfp_intensity_results.append({\n",
    "                    \"Identifier\": identifier,\n",
    "                    \"Mean_GFP_Intensity\": mean_gfp_intensity,\n",
    "                    \"Total_GFP_Intensity\": total_gfp_intensity\n",
    "                })\n",
    "\n",
    "                # Clear memory by deleting large arrays after processing\n",
    "                del phase_np, phase_rgb, mask, gfp_np, gfp_values_within_fish\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {identifier}: {e}\")  # Report error without stopping execution\n",
    "\n",
    "        # Print progress every 5 processed pairs\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(phase_contrast_files)} image pairs.\")\n",
    "\n",
    "    # Convert the results to a DataFrame and save to a CSV file\n",
    "    results_df = pd.DataFrame(gfp_intensity_results)\n",
    "    csv_output_path = os.path.join(output_dir, \"gfp_intensity_results.csv\")\n",
    "    results_df.to_csv(csv_output_path, index=False)\n",
    "    \n",
    "    print(f\"Results saved to {csv_output_path}\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for loading and saving images\n",
    "input_dir = r\"C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\test_images\"\n",
    "output_dir = r\"C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\Output_test_images\"\n",
    "phase_mask_dir = os.path.join(output_dir, \"phase_masks\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\Output_test_images\\gfp_intensity_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the function on the directory with options for saving images and masked images\n",
    "gfp_intensity_results_df = process_images(input_dir, output_dir, save_masks=True, save_masked_images=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MoIm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
