{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths for loading and saving images -> from optimized version\n",
    "input_dir = r\"C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\First_batch\"\n",
    "output_dir = r\"C:\\Users\\dave-\\OneDrive - ZHAW\\HS24\\MoIm\\MolecularIMaging\\Images\\Output_first_batch\"\n",
    "phase_mask_dir = os.path.join(output_dir, \"phase_masks\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dave-\\anaconda3\\envs\\MoIm\\Lib\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "# Load SAM Model\n",
    "model_type = \"vit_h\"  # Model type can be \"vit_h\", \"vit_l\", or \"vit_b\"\n",
    "sam = sam_model_registry[model_type](checkpoint=\"./sam_vit_h_4b8939.pth\")\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract a unique identifier from a filename based on a pattern.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): The filename of the image.\n",
    "    \n",
    "    Returns:\n",
    "        str: A unique identifier combining the first two parts and last three digits of the filename.\n",
    "        Returns None if the filename doesn't match the expected pattern.\n",
    "    \"\"\"\n",
    "    match = re.match(r\"^([A-H]\\d+_\\d+).*_(\\d{3})\\.tif$\", filename)\n",
    "    return f\"{match.group(1)}_{match.group(2)}\" if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(input_dir: str, output_dir: str, \n",
    "                   save_masks: bool = False, save_masked_images: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process pairs of 'Phase Contrast' and 'GFP' images to calculate GFP intensity within \n",
    "    the segmented zebrafish region and save results in a DataFrame.\n",
    "    \n",
    "    The function:\n",
    "    1. Matches pairs of 'Phase Contrast' and 'GFP' images based on unique identifiers.\n",
    "    2. Generates a binary mask of the zebrafish in the 'Phase Contrast' image using SAM.\n",
    "    3. Calculates mean and total GFP intensity within the masked region of the corresponding GFP image.\n",
    "    4. Saves the results in a DataFrame.\n",
    "    5. Optionally saves the generated mask and masked GFP images.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Directory containing the input TIF images.\n",
    "        output_dir (str): Directory to save output files (masks and results).\n",
    "        save_masks (bool): If True, saves the generated masks as PNG files.\n",
    "        save_masked_images (bool): If True, saves the masked GFP images.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with GFP intensity data for each image pair.\n",
    "    \"\"\"\n",
    "    # Set phase_mask_dir only if save_masks is True\n",
    "    phase_mask_dir = os.path.join(output_dir, \"phase_masks\")\n",
    "    if save_masks:\n",
    "        os.makedirs(phase_mask_dir, exist_ok=True)\n",
    "\n",
    "    # Collect Phase Contrast and GFP files based on unique identifier\n",
    "    phase_contrast_files = {}\n",
    "    gfp_files = {}\n",
    "    \n",
    "    # Iterate through files to categorize Phase Contrast and GFP images by unique identifier\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith(\".tif\"):\n",
    "            identifier = get_identifier(file_name)\n",
    "            if identifier:\n",
    "                if \"Phase Contrast\" in file_name:\n",
    "                    phase_contrast_files[identifier] = file_name\n",
    "                elif \"GFP\" in file_name:\n",
    "                    gfp_files[identifier] = file_name\n",
    "\n",
    "    # List to store GFP intensity results for each identifier\n",
    "    gfp_intensity_results = []\n",
    "\n",
    "    # Process each pair of Phase Contrast and GFP files\n",
    "    for identifier, phase_file in phase_contrast_files.items():\n",
    "        if identifier in gfp_files:\n",
    "            # Load Phase Contrast and GFP images\n",
    "            phase_path = os.path.join(input_dir, phase_file)\n",
    "            gfp_path = os.path.join(input_dir, gfp_files[identifier])\n",
    "            \n",
    "            # Generate mask from the Phase Contrast image\n",
    "            phase_image = Image.open(phase_path)\n",
    "            phase_np = np.array(phase_image)\n",
    "            \n",
    "            # Convert from uint16 to uint8 by normalizing the pixel values\n",
    "            phase_np = (phase_np / phase_np.max() * 255).astype(np.uint8)\n",
    "            \n",
    "            # Convert grayscale to RGB by stacking along the third dimension for SAM compatibility\n",
    "            phase_rgb = np.stack([phase_np] * 3, axis=-1)\n",
    "            \n",
    "            # Set the image in SAM model for mask generation\n",
    "            predictor.set_image(phase_rgb)\n",
    "\n",
    "            # Define a point on the zebrafish (midpoint of the image)\n",
    "            input_point = np.array([[phase_rgb.shape[1] // 2, phase_rgb.shape[0] // 2]])  # Midpoint of the image\n",
    "            input_label = np.array([1])  # Label '1' for foreground\n",
    "\n",
    "            # Generate mask based on the input point\n",
    "            masks, scores, _ = predictor.predict(\n",
    "                point_coords=input_point,\n",
    "                point_labels=input_label,\n",
    "                multimask_output=False\n",
    "            )\n",
    "            mask = masks[0]  # Retrieve the primary mask\n",
    "            \n",
    "            # Optionally save the generated mask as a PNG for visual confirmation\n",
    "            if save_masks:\n",
    "                mask_output_path = os.path.join(phase_mask_dir, f\"mask_{os.path.splitext(phase_file)[0]}.png\")\n",
    "                Image.fromarray((mask * 255).astype(np.uint8)).save(mask_output_path)\n",
    "\n",
    "            # Load GFP image and calculate GFP intensity within the mask\n",
    "            gfp_image = Image.open(gfp_path)\n",
    "            gfp_np = np.array(gfp_image)\n",
    "\n",
    "            # Apply the mask to isolate GFP values within the fish\n",
    "            gfp_masked = gfp_np * mask  # Apply the mask to the GFP image\n",
    "            gfp_values_within_fish = gfp_np[mask > 0]\n",
    "\n",
    "            # Calculate mean and total GFP intensity within the fish\n",
    "            mean_gfp_intensity = gfp_values_within_fish.mean()\n",
    "            total_gfp_intensity = gfp_values_within_fish.sum()\n",
    "\n",
    "            # Optionally save the masked GFP image\n",
    "            if save_masked_images:\n",
    "                output_path = os.path.join(output_dir, f\"masked_{gfp_files[identifier]}.png\")\n",
    "                Image.fromarray(gfp_masked).save(output_path)\n",
    "\n",
    "            # Append the results to the list\n",
    "            gfp_intensity_results.append({\n",
    "                \"Identifier\": identifier,\n",
    "                \"Mean_GFP_Intensity\": mean_gfp_intensity,\n",
    "                \"Total_GFP_Intensity\": total_gfp_intensity\n",
    "            })\n",
    "\n",
    "    # Convert the results to a DataFrame\n",
    "    results_df = pd.DataFrame(gfp_intensity_results)\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    csv_output_path = os.path.join(output_dir, \"gfp_intensity_results.csv\")\n",
    "    results_df.to_csv(csv_output_path, index=False)\n",
    "    \n",
    "    print(f\"Results saved to {csv_output_path}\")\n",
    "    \n",
    "    # Return the DataFrame with results\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function on the directory with options for saving images and masked images\n",
    "gfp_intensity_results_df = process_images(input_dir, output_dir, save_masks=True, save_masked_images=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MoIm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
